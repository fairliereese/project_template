{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a2404c29-2d11-4c4e-bd33-516103a286a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Append resources dir to path\n",
    "p = os.path.dirname(os.getcwd())+'/resources/'\n",
    "sys.path.append(p)\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4dda0201-6e71-4f07-b92a-7c5326ff2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save mn5 version of config\n",
    "# save_mn5_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3ec675c-770f-4d54-98c8-6303f6469d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branch_url():\n",
    "    \"\"\"\n",
    "    Construct the GitHub URL for the current branch of the repository.\n",
    "\n",
    "    This function determines the name of the current Git branch using\n",
    "    ``git branch --show-current`` and constructs a URL pointing to the\n",
    "    root of that branch on GitHub. The base GitHub repository URL must\n",
    "    be provided by ``load_resources()`` as ``m['gh_url']``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A URL string pointing to the root of the current branch on GitHub,\n",
    "        formatted as: ``<gh_url>tree/<branch_name>/``.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Example output for the ``main`` branch:\n",
    "      ``https://github.com/user/repo/tree/main/``.\n",
    "    \"\"\"\n",
    "    m = load_resources()\n",
    "    cmd = 'git branch --show-current'\n",
    "    b = run_cmd(cmd)\n",
    "    b = b.strip()\n",
    "    branch_url = f\"{m['gh_url']}tree/{b}/\"\n",
    "    return branch_url\n",
    "\n",
    "def find_missing_subdirs(d):\n",
    "    \"\"\"\n",
    "    Identify subdirectories within a given directory that are not referenced in its README.\n",
    "\n",
    "    This function checks each subdirectory of the specified directory `d` and compares\n",
    "    its name against entries in the corresponding `README.md` file. Certain permanent\n",
    "    directories (e.g., 'rules', 'template_snakemake') are ignored. Subdirectories not\n",
    "    found in the README are collected and returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : str\n",
    "        Name of the parent directory to scan. Typically 'processing'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of pathlib.Path\n",
    "        List of subdirectory paths that are missing from the README. If all subdirectories\n",
    "        are listed in the README, the list will be empty.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Permanent directories defined for 'processing' are ['rules', 'template_snakemake'].\n",
    "    - The function assumes the README is located at '../<d>/README.md'.\n",
    "    - Only immediate subdirectories of `d` are checked, not nested ones.\n",
    "    \"\"\"\n",
    "\n",
    "    to_update = []\n",
    "\n",
    "    if d == 'processing':\n",
    "        perm_dirs = ['rules', 'template_snakemake', '.ipynb_checkpoints']\n",
    "    elif d == 'analysis':\n",
    "        perm_dirs = ['.ipynb_checkpoints']\n",
    "    else: perm_dirs = []\n",
    "\n",
    "    readme = f'../{d}/README.md'\n",
    "\n",
    "    # loop through each valid subdir\n",
    "    for sub_d in Path(f'../{d}/').glob('*/'):\n",
    "        stem_sub_d = sub_d.stem\n",
    "        if stem_sub_d in perm_dirs: continue\n",
    "        if not sub_d.is_dir(): continue\n",
    "\n",
    "        fmt_sub_d = f'[{stem_sub_d}]'\n",
    "        if any(fmt_sub_d in line for line in open(readme)): continue\n",
    "        to_update.append(sub_d)\n",
    "        \n",
    "    return to_update\n",
    "\n",
    "def add_missing_subdirs_to_readme(d, missing_dirs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Append missing subdirectory entries to the appropriate section of a README.\n",
    "\n",
    "    This function reads the README file for a given top-level directory (`d`) and\n",
    "    appends bullet points for any subdirectories listed in `missing_dirs` that\n",
    "    are not already present. The new bullets are inserted just before the next\n",
    "    section header in the README.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : str\n",
    "        Top-level directory name. Currently, only 'processing' and 'analysis'\n",
    "        are supported.\n",
    "    missing_dirs : list of pathlib.Path\n",
    "        List of subdirectory paths that should be added to the README as bullet points.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function assumes the README is located at '../<d>/README.md'.\n",
    "    - For 'processing', bullets are added under the section titled\n",
    "      '## Subfolder descriptions'.\n",
    "    - Each bullet is formatted as:\n",
    "        * [<subdirectory_name>](<repo_url>/<subdirectory_path>/): # TODO!!\n",
    "    - The variable `m['gh_url']` must be defined externally to provide the repository URL.\n",
    "    - The function preserves all other content and headers in the README.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # load resources to get GH URL\n",
    "    m = load_resources()   \n",
    "    inserted = False\n",
    "    \n",
    "    \n",
    "    # if d == 'processing':\n",
    "    header = \"## Subfolder descriptions\"\n",
    "    # elif d == 'analysis':\n",
    "        # raise ValueError('You havent made this yet')\n",
    "    \n",
    "    # Read the README\n",
    "    readme = f'../{d}/README.md'\n",
    "    with open(readme, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    output_lines = []\n",
    "    inside_section = False\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        output_lines.append(line)\n",
    "\n",
    "        # find first relevant bullet\n",
    "        if header in line:\n",
    "            inside_section = True\n",
    "            continue\n",
    "\n",
    "        # Detect end of bullet list (next header)\n",
    "        if inside_section:\n",
    "            if line.startswith(\"## \"):\n",
    "                # insert new bullets just before the break\n",
    "                last_bullet_idx = max(i for i, line in enumerate(output_lines) if \"* [\"  in line.strip())\n",
    "                for i, sub_d in enumerate(missing_dirs):\n",
    "                    stem_sub_d = sub_d.stem\n",
    "                    output_lines.insert(last_bullet_idx+i+1, f\"* [{stem_sub_d}]({m['gh_url']}/{sub_d}/): # TODO!! \\n\")\n",
    "                output_lines.insert(-2, '\\n')\n",
    "                inside_section = False\n",
    "                inserted = True\n",
    "    \n",
    "    # if we had to wait for end of file\n",
    "    if inserted == False:\n",
    "        for i, sub_d in enumerate(missing_dirs):\n",
    "            stem_sub_d = sub_d.stem\n",
    "            output_lines.append(f\"* [{stem_sub_d}]({stem_sub_d}/): # TODO!! \")\n",
    "            output_lines.append('\\n')\n",
    "\n",
    "    # Write back updated README\n",
    "    with open(readme, 'w') as outfile:\n",
    "        outfile.writelines(output_lines)\n",
    "                     \n",
    "    # write to user where README entries have been written\n",
    "    if len(missing_dirs) > 0:\n",
    "        print(f\"Added README entries to {readme.split('../')[1]} for \")\n",
    "        for sub_d in missing_dirs:\n",
    "            print(f'- {sub_d.stem}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2883da96-4fdd-4f10-8b13-9eb3f26c7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all missing dirs to output note to user eventually\n",
    "all_missing_dirs = []\n",
    "\n",
    "# processing\n",
    "d = 'processing'\n",
    "missing_dirs = find_missing_subdirs(d)\n",
    "add_missing_subdirs_to_readme(d, missing_dirs)\n",
    "all_missing_dirs += missing_dirs\n",
    "\n",
    "# analysis\n",
    "d = 'analysis'\n",
    "missing_dirs = find_missing_subdirs(d)\n",
    "add_missing_subdirs_to_readme(d, missing_dirs)\n",
    "all_missing_dirs += missing_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "459d3f58-9ca9-4668-935d-b33eaf649b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://github.com/pclavell/project_template/tree/gh_actions/\n",
      "http://github.com/pclavell/project_template/\n"
     ]
    }
   ],
   "source": [
    "print(get_branch_url())\n",
    "print(load_resources()['gh_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac8093c6-13c0-43b6-855e-23f83276827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all README links using the GH url for correct branch, if neccessary\n",
    "for readme in Path(f'../').rglob('README.md'):\n",
    "       \n",
    "    # repo_path = Path(str(readme).split('../')[1]).parents[0]\n",
    "    repo_path = readme.parents[0]\n",
    "    print(repo_path)\n",
    "    \n",
    "    files = [str(f).split('../')[1] for f in repo_path.rglob('*')]\n",
    "    files = sorted(files, key=lambda f: len(Path(f).parts), reverse=True)\n",
    "    print(files)\n",
    "    \n",
    "    # parse readme to see if any of these files are mentioned here\n",
    "    with open(readme, 'r') as infile:\n",
    "    #     for line in infile:\n",
    "            \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01088f-20db-4219-b127-585ae7c9e524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c157e3-6ff3-407e-9726-42e0e5bb74cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20954ad6-ee47-40b3-a92f-88d7e814f626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9614e-313a-474a-905d-9f5fe4ad3f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a3161-35c1-478a-9851-6193f52327e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7bfac-2e66-4d71-9485-b83957ac2a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f6fe313-9312-41e4-876b-073430477805",
   "metadata": {},
   "source": [
    "## Going to try a different strategy 250910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "955b4f09-d5af-4a08-88f2-7c9b1759d775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.yml',\n",
       " 'save_mn5_config.py',\n",
       " 'utils.r',\n",
       " 'utils.py',\n",
       " 'resources.yml',\n",
       " 'TEST.md',\n",
       " 'git_push_companion.ipynb',\n",
       " 'smk_utils.py',\n",
       " 'init_gh_url.py']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all git files\n",
    "cmd = 'git ls-files'\n",
    "files = run_cmd(cmd).splitlines()\n",
    "dirs = [str(Path(f).parent) for f in files]\n",
    "files = [f for f in list(set(files)|set(dirs)) if f != '.']\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88f5d90a-9b73-468a-aa98-b86902ed24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "files = ['analysis', 'analysis/template.R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "89f0c375-1f3f-4f64-aebe-f271124b8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown parsing one word at a time\n",
    "from marko import Markdown\n",
    "from marko.ast_renderer import ASTRenderer\n",
    "md_files = ['TEST.md']\n",
    "# md_files = ['TEST_2.md']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0ff5e1dc-a458-4596-bda3-234c9c6019b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document children=[<Paragraph children=[<RawText children='We want to look in the analysis directory.'>]>,\n",
      " <BlankLine children=[]>,\n",
      " <Paragraph children=[<RawText children='To see how to run R code, take a look at analysis/template.R.'>]>,\n",
      " <BlankLine children=[]>,\n",
      " <Paragraph children=[<RawText children='Hello, '>,\n",
      " <Link children=[<RawText children='This is a link'>]>]>,\n",
      " <BlankLine children=[]>,\n",
      " <FencedCode children=[<RawText children='this is code analysis\\nthis is some more code analysis\\n'>]>,\n",
      " <BlankLine children=[]>,\n",
      " <HTMLBlock children=[]>,\n",
      " <BlankLine children=[]>,\n",
      " <List children=[<ListItem children=[<Paragraph children=[<RawText children='This is a bullet point'>]>]>,\n",
      " <ListItem children=[<List children=[<ListItem children=[<Paragraph children=[<RawText children='this is a nested bullet point'>]>]>]>]>,\n",
      " <ListItem children=[<List children=[<ListItem children=[<Paragraph children=[<RawText children='this is a nested bullet point analysis.'>]>]>]>]>]>]>\n",
      "We want to look in the [`analysis`](analysis) directory.\n",
      "<Document children=[<Paragraph children=[<RawText children='We want to look in the '>,\n",
      " <Link children=[<CodeSpan children='analysis'>]>,\n",
      " <RawText children=' directory.'>]>]>\n",
      "To see how to run R code, take a look at [`analysis/template.R`](analysis/template.R).\n",
      "<Document children=[<Paragraph children=[<RawText children='To see how to run R code, take a look at '>,\n",
      " <Link children=[<CodeSpan children='analysis/template.R'>]>,\n",
      " <RawText children='.'>]>]>\n",
      "Hello,\n",
      "<Document children=[<Paragraph children=[<RawText children='Hello,'>]>]>\n",
      "This is a link\n",
      "<Document children=[<Paragraph children=[<RawText children='This is a link'>]>]>\n",
      "This is a bullet point\n",
      "<Document children=[<Paragraph children=[<RawText children='This is a bullet point'>]>]>\n",
      "this is a nested bullet point\n",
      "<Document children=[<Paragraph children=[<RawText children='this is a nested bullet point'>]>]>\n",
      "this is a nested bullet point [`analysis`](analysis).\n",
      "<Document children=[<Paragraph children=[<RawText children='this is a nested bullet point '>,\n",
      " <Link children=[<CodeSpan children='analysis'>]>,\n",
      " <RawText children='.'>]>]>\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from marko import Markdown\n",
    "from marko.md_renderer import MarkdownRenderer\n",
    "from marko.inline import RawText, Link, CodeSpan\n",
    "from marko.block import FencedCode, CodeBlock\n",
    "\n",
    "def format_link(word):\n",
    "    \"\"\"\n",
    "    Format link in markdown depending on if it's a \n",
    "    directory or a file\n",
    "    \"\"\"\n",
    "    if Path(word).is_dir():\n",
    "        l = f'[{word}]({word})'\n",
    "    else:\n",
    "        l = f'[`{word}`]({word})'\n",
    "    return l\n",
    "\n",
    "def link_files(node, files):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # skip entire code blocks\n",
    "    if isinstance(node, (FencedCode, CodeBlock)):\n",
    "        return node\n",
    "\n",
    "    # skip inline code spans\n",
    "    if isinstance(node, CodeSpan):\n",
    "        return node\n",
    "    \n",
    "    # skip existing links\n",
    "    if isinstance(node, Link):\n",
    "        return node\n",
    "\n",
    "\n",
    "    # If raw text, split and replace words\n",
    "    if isinstance(node, RawText):\n",
    "        words = []\n",
    "        for word in node.children.split():\n",
    "            add_period = False\n",
    "            if word.endswith('.'):\n",
    "                add_period = True\n",
    "                word = word[:-1]\n",
    "            if word in files:\n",
    "                words.append(format_link(word))\n",
    "            else:\n",
    "                words.append(word)\n",
    "            if add_period == True:\n",
    "                words[-1] += '.'\n",
    "                add_period = False\n",
    "            \n",
    "        words = ' '.join(words)\n",
    "        print(words)\n",
    "        md = Markdown()\n",
    "        words = md.parse(words)\n",
    "        print(words)\n",
    "        \n",
    "        return words\n",
    "\n",
    "    # If it has children, recurse\n",
    "    if hasattr(node, \"children\"):\n",
    "        new_children = []\n",
    "        for child in node.children:\n",
    "            replaced = link_files(child, files)\n",
    "            if isinstance(replaced, list):\n",
    "                new_children.extend(replaced)\n",
    "            else:\n",
    "                new_children.append(replaced)\n",
    "        node.children = new_children\n",
    "    return node\n",
    "\n",
    "md = Markdown()\n",
    "with open(md_files[0], 'r') as f:\n",
    "    content = f.read()\n",
    "    doc = md.parse(content)\n",
    "    \n",
    "print(doc)\n",
    "\n",
    "doc = link_files(doc, files)\n",
    "    \n",
    "md = Markdown(renderer=MarkdownRenderer)\n",
    "doc = md.render(doc)\n",
    "\n",
    "# Write to new md file\n",
    "with open('TEST_revised.md', 'w') as ofile:\n",
    "    ofile.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8aee18-66bb-4774-8f6a-9b9b25b3fa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'element': 'raw_text',\n",
       " 'children': 'We want to look in the analysis directory.',\n",
       " 'escape': True}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (ast['children'][0]['children'][0]).get('element')\n",
    "# ast['children'][0]['children'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996101da-67af-4a1a-a3c8-33427d9c9c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbe917-91d3-4fb8-9746-387054e2df3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7e977-c8a6-4b51-99aa-dd0bf5e00c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ee1a00-def3-4c35-b4a3-faeeb1881823",
   "metadata": {},
   "source": [
    "## testing gh workflow 250909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a2f45e4-dc67-479a-8127-105755cead54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: Link Files in README\n",
      "\n",
      "on:\n",
      "  push:\n",
      "    paths:\n",
      "      - 'template_user/resources/TEST.md'  # Change to '**/*.md' after testing\n",
      "\n",
      "jobs:\n",
      "  link-files:\n",
      "    runs-on: ubuntu-latest\n",
      "    steps:\n",
      "      - uses: actions/checkout@v4\n",
      "\n",
      "      - name: Replace references to analysis/template.R\n",
      "        uses: jacobtomlinson/gha-find-replace@v3\n",
      "        with:\n",
      "          find: '(^|\\W)(analysis/template\\.R)(\\W|$)'\n",
      "          replace: '\\1[`analysis/template.R`](http://github.com/pclavell/project_template/tree/gh_actions/analysis/template.R)\\3'\n",
      "          include: 'template_user/resources/TEST.md'\n",
      "          regex: true\n",
      "    \n",
      "      - name: Replace references to analysis\n",
      "        uses: jacobtomlinson/gha-find-replace@v3\n",
      "        with:\n",
      "          find: '(^|\\W)(analysis)(\\W|$)'\n",
      "          replace: '\\1[`analysis`](http://github.com/pclavell/project_template/tree/gh_actions/analysis)\\3'\n",
      "          include: 'template_user/resources/TEST.md'\n",
      "          regex: true\n",
      "    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../../.github/workflows/link-files-test.yml')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "files = [\n",
    "    'analysis/template.R',\n",
    "    'analysis'\n",
    "]\n",
    "\n",
    "files = [Path(f) for f in files]\n",
    "repo_path = Path('.')  # adjust if needed\n",
    "\n",
    "# Convert to relative POSIX paths\n",
    "files_rel = [f.relative_to(repo_path).as_posix() for f in files]\n",
    "\n",
    "# Build a separate step for each file\n",
    "steps_yaml = \"\"\n",
    "\n",
    "for f in files_rel:\n",
    "    escaped_file = re.escape(f)\n",
    "    f = Path(f)\n",
    "    \n",
    "    if f.is_dir():\n",
    "        regex = rf\"(^|\\W)({escaped_file})(\\W|$)\"\n",
    "        replacement = rf\"\\1[{f}]({get_branch_url()}{f})\\3\"\n",
    "    else:\n",
    "        regex = rf\"(^|\\W)({escaped_file})(\\W|$)\"\n",
    "        replacement = rf\"\\1[`{f}`]({get_branch_url()}{f})\\3\"\n",
    "\n",
    "\n",
    "#     if f.is_dir():\n",
    "#         regex = rf\"\\b{escaped_file}\\b(?!/)\"\n",
    "        \n",
    "#         replacement = f\"[{f}]({get_branch_url()}{f})\"\n",
    "#     else:\n",
    "#         regex = rf\"\\b{escaped_file}\\b\"\n",
    "#         replacement = f\"[`{f}`]({get_branch_url()}{f})\"\n",
    "\n",
    "\n",
    "    step = f\"\"\"\n",
    "      - name: Replace references to {f}\n",
    "        uses: jacobtomlinson/gha-find-replace@v3\n",
    "        with:\n",
    "          find: '{regex}'\n",
    "          replace: '{replacement}'\n",
    "          include: 'template_user/resources/TEST.md'\n",
    "          regex: true\n",
    "    \"\"\"\n",
    "    steps_yaml += step\n",
    "\n",
    "# Full GitHub Action YAML\n",
    "yaml_snippet = f\"\"\"\n",
    "name: Link Files in README\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    paths:\n",
    "      - 'template_user/resources/TEST.md'  # Change to '**/*.md' after testing\n",
    "\n",
    "jobs:\n",
    "  link-files:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "{steps_yaml}\n",
    "\"\"\"\n",
    "\n",
    "print(yaml_snippet)\n",
    "\n",
    "# Save workflow\n",
    "workflow_dir = Path('../../.github/workflows')  # relative to resources/\n",
    "workflow_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "workflow_file = workflow_dir / 'link-files-test.yml'\n",
    "workflow_file.write_text(yaml_snippet)\n",
    "\n",
    "workflow_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa2d78b2-080f-4501-8e9d-e517f76fc501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote workflow to: /Users/fairliereese/Documents/programming/mele_lab/projects/project_template/.github/workflows/link-files-test.yml\n",
      "Workflow preview:\n",
      "\n",
      "\n",
      "name: Link Files in README\n",
      "\n",
      "on:\n",
      "  push:\n",
      "    paths:\n",
      "      - 'template_user/resources/TEST.md'  # Change to '**/*.md' after testing\n",
      "\n",
      "jobs:\n",
      "  link-files:\n",
      "    runs-on: ubuntu-latest\n",
      "    steps:\n",
      "      - uses: actions/checkout@v4\n",
      "      - name: Replace occurrences of analysis/template.R with placeholder\n",
      "        uses: jacobtomlinson/gha-find-replace@v3\n",
      "        with:\n",
      "          find: '\\banalysis/template\\.R\\b'\n",
      "          replace: '__FILE_REPL_1_1819D1B9__'\n",
      "          include: 'template_user/resources/TEST.md'\n",
      "          regex: true\n",
      "      - name: Replace occurrences of analysis with placeholder\n",
      "        uses: jacobtomlinson/gha-find-replace@v3\n",
      "        with:\n",
      "          find: '\\banalysis\\b'\n",
      "          replace: '__FILE_REPL_2_889E0153__'\n",
      "          include: 'template_user/resources/TEST.md'\n",
      "          regex: true\n",
      "      - name: Restore placeholder __FILE_REPL_1_1819D1B9__ -> link for analysis/template.R\n",
      "        uses: jacobtomlinson/gha-find-replace@v3\n",
      "        with:\n",
      "          find: '__FILE_REPL_1_1819D1B9__'\n",
      "          replace: '[`analysis/template.R`](http://github.com/pclavell/project_template/tree/gh_actions/analysis/template.R)'\n",
      "          include: 'template_user/resources/TEST.md'\n",
      "          regex: false\n",
      "      - name: Restore placeholder __FILE_REPL_2_889E0153__ -> link for analysis\n",
      "        uses: jacobtomlinson/gha-find-replace@v3\n",
      "        with:\n",
      "          find: '__FILE_REPL_2_889E0153__'\n",
      "          replace: '[`analysis`](http://github.com/pclavell/project_template/tree/gh_actions/analysis)'\n",
      "          include: 'template_user/resources/TEST.md'\n",
      "          regex: false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "# -------------------------\n",
    "# User inputs / setup\n",
    "# -------------------------\n",
    "files = [\n",
    "    'analysis/template.R',\n",
    "    'analysis'\n",
    "]\n",
    "\n",
    "repo_path = Path('.')  # adjust if needed\n",
    "target_md = Path('template_user/resources/TEST.md')\n",
    "workflow_dir = Path('../../.github/workflows')  # relative to resources/\n",
    "workflow_file = workflow_dir / 'link-files-test.yml'\n",
    "\n",
    "# assume get_branch_url() is defined elsewhere as you requested\n",
    "# def get_branch_url(): return \"https://github.com/me/repo/blob/main/\"\n",
    "\n",
    "# -------------------------\n",
    "# Helper: YAML single-quote escape\n",
    "# -------------------------\n",
    "def yaml_single_quote(s: str) -> str:\n",
    "    # YAML single-quoted string: single quotes are escaped by doubling them.\n",
    "    return \"'\" + s.replace(\"'\", \"''\") + \"'\"\n",
    "\n",
    "# -------------------------\n",
    "# Read current file and extract existing inline markdown links\n",
    "# (we'll mask these and restore later)\n",
    "# -------------------------\n",
    "content = ''\n",
    "if target_md.exists():\n",
    "    content = target_md.read_text(encoding='utf-8')\n",
    "\n",
    "# find inline markdown links like [text](url)\n",
    "link_pattern = re.compile(r'\\[[^\\]]+\\]\\([^\\)]+\\)')\n",
    "existing_links = [m.group(0) for m in link_pattern.finditer(content)]\n",
    "\n",
    "# Build mapping original -> placeholder (unique)\n",
    "masked_links = []\n",
    "for i, orig in enumerate(existing_links, start=1):\n",
    "    placeholder = f\"__MDLINK_{i}__\"\n",
    "    masked_links.append((orig, placeholder))\n",
    "\n",
    "# -------------------------\n",
    "# Prepare file list (relative POSIX), sort by descending length to avoid recursion\n",
    "# -------------------------\n",
    "files = [Path(f) for f in files]\n",
    "files_rel = [f.relative_to(repo_path).as_posix() for f in files]\n",
    "# sort by length (longest first) to prevent recursive partial replacements\n",
    "files_sorted = sorted(files_rel, key=lambda s: len(s), reverse=True)\n",
    "\n",
    "# -------------------------\n",
    "# Helper to create a unique placeholder for each file replacement\n",
    "# -------------------------\n",
    "def make_file_placeholder(i: int) -> str:\n",
    "    # include short uuid so placeholders are extremely unlikely to collide with real text\n",
    "    return f\"__FILE_REPL_{i}_{uuid.uuid4().hex[:8].upper()}__\"\n",
    "\n",
    "# -------------------------\n",
    "# Build workflow steps YAML\n",
    "# -------------------------\n",
    "steps_yaml = \"\"\n",
    "\n",
    "# 1) checkout step (keep this first)\n",
    "steps_yaml += \"\"\"      - uses: actions/checkout@v4\n",
    "\"\"\"\n",
    "\n",
    "# 2) mask existing markdown links (literal replace, regex: false)\n",
    "for orig, placeholder in masked_links:\n",
    "    steps_yaml += f\"\"\"      - name: Mask existing MD link -> {placeholder}\n",
    "        uses: jacobtomlinson/gha-find-replace@v3\n",
    "        with:\n",
    "          find: {yaml_single_quote(orig)}\n",
    "          replace: {yaml_single_quote(placeholder)}\n",
    "          include: '{target_md.as_posix()}'\n",
    "          regex: false\n",
    "\"\"\"\n",
    "\n",
    "# 3) replace each file path with a unique placeholder (regex-based find; replacement literal placeholder)\n",
    "file_placeholders = []  # list of tuples (file_rel, placeholder, is_dir_bool)\n",
    "for i, f_rel in enumerate(files_sorted, start=1):\n",
    "    p = Path(f_rel)\n",
    "    escaped_file = re.escape(f_rel)           # escape for regex\n",
    "    # pattern: use \\b boundary on both sides (RE2/Go accepts \\b). This is simple and avoids lookarounds.\n",
    "    pattern = rf\"\\b{escaped_file}\\b\"\n",
    "    placeholder = make_file_placeholder(i)\n",
    "    file_placeholders.append((f_rel, placeholder, p.is_dir()))\n",
    "\n",
    "    steps_yaml += f\"\"\"      - name: Replace occurrences of {f_rel} with placeholder\n",
    "        uses: jacobtomlinson/gha-find-replace@v3\n",
    "        with:\n",
    "          find: {yaml_single_quote(pattern)}\n",
    "          replace: {yaml_single_quote(placeholder)}\n",
    "          include: '{target_md.as_posix()}'\n",
    "          regex: true\n",
    "\"\"\"\n",
    "\n",
    "# 4) restore placeholders -> real Markdown links (literal replacements, regex: false)\n",
    "#    (We use get_branch_url() here as you asked; do not redefine it.)\n",
    "for f_rel, placeholder, is_dir in file_placeholders:\n",
    "    # Build target replacement Markdown\n",
    "    if is_dir:\n",
    "        replacement = f\"[{f_rel}]({get_branch_url()}{f_rel})\"\n",
    "    else:\n",
    "        replacement = f\"[`{f_rel}`]({get_branch_url()}{f_rel})\"\n",
    "\n",
    "    steps_yaml += f\"\"\"      - name: Restore placeholder {placeholder} -> link for {f_rel}\n",
    "        uses: jacobtomlinson/gha-find-replace@v3\n",
    "        with:\n",
    "          find: {yaml_single_quote(placeholder)}\n",
    "          replace: {yaml_single_quote(replacement)}\n",
    "          include: '{target_md.as_posix()}'\n",
    "          regex: false\n",
    "\"\"\"\n",
    "\n",
    "# 5) finally, restore any original markdown links we masked earlier\n",
    "for orig, placeholder in masked_links:\n",
    "    steps_yaml += f\"\"\"      - name: Restore original MD link {placeholder} -> original\n",
    "        uses: jacobtomlinson/gha-find-replace@v3\n",
    "        with:\n",
    "          find: {yaml_single_quote(placeholder)}\n",
    "          replace: {yaml_single_quote(orig)}\n",
    "          include: '{target_md.as_posix()}'\n",
    "          regex: false\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# Wrap into a full workflow YAML\n",
    "# -------------------------\n",
    "yaml_snippet = f\"\"\"\n",
    "name: Link Files in README\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    paths:\n",
    "      - '{target_md.as_posix()}'  # Change to '**/*.md' after testing\n",
    "\n",
    "jobs:\n",
    "  link-files:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "{steps_yaml}\n",
    "\"\"\"\n",
    "\n",
    "# ensure workflow dir exists and write\n",
    "workflow_dir.mkdir(parents=True, exist_ok=True)\n",
    "workflow_file.write_text(yaml_snippet, encoding='utf-8')\n",
    "\n",
    "print(f\"Wrote workflow to: {workflow_file.resolve()}\")\n",
    "print(\"Workflow preview:\\n\")\n",
    "print(yaml_snippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4b578-b807-4c50-af99-55fa84e467cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f6f72-4348-4400-b6d4-99d12553bf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f543a6f-71cf-4637-94b1-848cad328e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060f884-76a0-4749-95ff-93af9ba1838f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87da1b3a-1055-4cf6-a71e-e8a75ca40b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build one regex that matches any file in backticks or brackets\n",
    "# import re\n",
    "# # files = ['analysis/template.R', 'resources/resources.yml', 'resources']\n",
    "# files = ['analysis']\n",
    "# escaped_files = [re.escape(f) for f in files]\n",
    "# pattern = r'(`(' + '|'.join(escaped_files) + r')`|\\[(' + '|'.join(escaped_files) + r')\\])'\n",
    "# pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87a6f0aa-11b0-44bd-8069-bbc4f03dcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readme = 'TEST.md'\n",
    "\n",
    "# files = [str(f).split('../')[1] for f in repo_path.rglob('*')]\n",
    "# files = sorted(files, key=lambda f: len(Path(f).parts), reverse=True)\n",
    "# print(files)\n",
    "\n",
    "# for f in files:\n",
    "#     lines = []\n",
    "#     with open(readme, 'r') as infile:\n",
    "#         for line in infile:\n",
    "#             # if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a5e73-2f65-44da-b37c-e32fc63e2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace already-there links with the one using the proper / updated branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379c8de-8129-4d12-b757-6b3894ef3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gh action to check for broken links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad08b6-b672-4239-9d80-bb82c15c49da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15856c5-6a7e-4af4-88b5-8d9242d9b29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
