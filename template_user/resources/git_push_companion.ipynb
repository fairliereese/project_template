{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2404c29-2d11-4c4e-bd33-516103a286a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Append resources dir to path\n",
    "p = os.path.dirname(os.getcwd())+'/resources/'\n",
    "sys.path.append(p)\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dda0201-6e71-4f07-b92a-7c5326ff2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save mn5 version of config\n",
    "# save_mn5_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ec675c-770f-4d54-98c8-6303f6469d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branch_url():\n",
    "    \"\"\"\n",
    "    Construct the GitHub URL for the current branch of the repository.\n",
    "\n",
    "    This function determines the name of the current Git branch using\n",
    "    ``git branch --show-current`` and constructs a URL pointing to the\n",
    "    root of that branch on GitHub. The base GitHub repository URL must\n",
    "    be provided by ``load_resources()`` as ``m['gh_url']``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A URL string pointing to the root of the current branch on GitHub,\n",
    "        formatted as: ``<gh_url>tree/<branch_name>/``.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Example output for the ``main`` branch:\n",
    "      ``https://github.com/user/repo/tree/main/``.\n",
    "    \"\"\"\n",
    "    m = load_resources()\n",
    "    cmd = 'git branch --show-current'\n",
    "    b = run_cmd(cmd)\n",
    "    b = b.strip()\n",
    "    branch_url = f\"{m['gh_url']}tree/{b}/\"\n",
    "    return branch_url\n",
    "\n",
    "def find_missing_subdirs(d):\n",
    "    \"\"\"\n",
    "    Identify subdirectories within a given directory that are not referenced in its README.\n",
    "\n",
    "    This function checks each subdirectory of the specified directory `d` and compares\n",
    "    its name against entries in the corresponding `README.md` file. Certain permanent\n",
    "    directories (e.g., 'rules', 'template_snakemake') are ignored. Subdirectories not\n",
    "    found in the README are collected and returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : str\n",
    "        Name of the parent directory to scan. Typically 'processing'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of pathlib.Path\n",
    "        List of subdirectory paths that are missing from the README. If all subdirectories\n",
    "        are listed in the README, the list will be empty.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Permanent directories defined for 'processing' are ['rules', 'template_snakemake'].\n",
    "    - The function assumes the README is located at '../<d>/README.md'.\n",
    "    - Only immediate subdirectories of `d` are checked, not nested ones.\n",
    "    \"\"\"\n",
    "\n",
    "    to_update = []\n",
    "\n",
    "    if d == 'processing':\n",
    "        perm_dirs = ['rules', 'template_snakemake', '.ipynb_checkpoints']\n",
    "    elif d == 'analysis':\n",
    "        perm_dirs = ['.ipynb_checkpoints']\n",
    "    else: perm_dirs = []\n",
    "\n",
    "    readme = f'../{d}/README.md'\n",
    "\n",
    "    # loop through each valid subdir\n",
    "    for sub_d in Path(f'../{d}/').glob('*/'):\n",
    "        stem_sub_d = sub_d.stem\n",
    "        if stem_sub_d in perm_dirs: continue\n",
    "        if not sub_d.is_dir(): continue\n",
    "\n",
    "        fmt_sub_d = f'[{stem_sub_d}]'\n",
    "        if any(fmt_sub_d in line for line in open(readme)): continue\n",
    "        to_update.append(sub_d)\n",
    "        \n",
    "    return to_update\n",
    "\n",
    "def add_missing_subdirs_to_readme(d, missing_dirs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Append missing subdirectory entries to the appropriate section of a README.\n",
    "\n",
    "    This function reads the README file for a given top-level directory (`d`) and\n",
    "    appends bullet points for any subdirectories listed in `missing_dirs` that\n",
    "    are not already present. The new bullets are inserted just before the next\n",
    "    section header in the README.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : str\n",
    "        Top-level directory name. Currently, only 'processing' and 'analysis'\n",
    "        are supported.\n",
    "    missing_dirs : list of pathlib.Path\n",
    "        List of subdirectory paths that should be added to the README as bullet points.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function assumes the README is located at '../<d>/README.md'.\n",
    "    - For 'processing', bullets are added under the section titled\n",
    "      '## Subfolder descriptions'.\n",
    "    - Each bullet is formatted as:\n",
    "        * [<subdirectory_name>](<repo_url>/<subdirectory_path>/): # TODO!!\n",
    "    - The variable `m['gh_url']` must be defined externally to provide the repository URL.\n",
    "    - The function preserves all other content and headers in the README.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # load resources to get GH URL\n",
    "    m = load_resources()   \n",
    "    inserted = False\n",
    "    \n",
    "    \n",
    "    # if d == 'processing':\n",
    "    header = \"## Subfolder descriptions\"\n",
    "    # elif d == 'analysis':\n",
    "        # raise ValueError('You havent made this yet')\n",
    "    \n",
    "    # Read the README\n",
    "    readme = f'../{d}/README.md'\n",
    "    with open(readme, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    output_lines = []\n",
    "    inside_section = False\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        output_lines.append(line)\n",
    "\n",
    "        # find first relevant bullet\n",
    "        if header in line:\n",
    "            inside_section = True\n",
    "            continue\n",
    "\n",
    "        # Detect end of bullet list (next header)\n",
    "        if inside_section:\n",
    "            if line.startswith(\"## \"):\n",
    "                # insert new bullets just before the break\n",
    "                last_bullet_idx = max(i for i, line in enumerate(output_lines) if \"* [\"  in line.strip())\n",
    "                for i, sub_d in enumerate(missing_dirs):\n",
    "                    stem_sub_d = sub_d.stem\n",
    "                    output_lines.insert(last_bullet_idx+i+1, f\"* [{stem_sub_d}]({m['gh_url']}/{sub_d}/): # TODO!! \\n\")\n",
    "                output_lines.insert(-2, '\\n')\n",
    "                inside_section = False\n",
    "                inserted = True\n",
    "    \n",
    "    # if we had to wait for end of file\n",
    "    if inserted == False:\n",
    "        for i, sub_d in enumerate(missing_dirs):\n",
    "            stem_sub_d = sub_d.stem\n",
    "            output_lines.append(f\"* [{stem_sub_d}]({m['gh_url']}/{sub_d}/): # TODO!! \")\n",
    "            output_lines.append('\\n')\n",
    "\n",
    "    # Write back updated README\n",
    "    with open(readme, 'w') as outfile:\n",
    "        outfile.writelines(output_lines)\n",
    "                     \n",
    "    # write to user where README entries have been written\n",
    "    if len(missing_dirs) > 0:\n",
    "        print(f\"Added README entries to {readme.split('../')[1]} for \")\n",
    "        for sub_d in missing_dirs:\n",
    "            print(f'- {sub_d.stem}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2883da96-4fdd-4f10-8b13-9eb3f26c7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all missing dirs to output note to user eventually\n",
    "all_missing_dirs = []\n",
    "\n",
    "# processing\n",
    "d = 'processing'\n",
    "missing_dirs = find_missing_subdirs(d)\n",
    "add_missing_subdirs_to_readme(d, missing_dirs)\n",
    "all_missing_dirs += missing_dirs\n",
    "\n",
    "# analysis\n",
    "d = 'analysis'\n",
    "missing_dirs = find_missing_subdirs(d)\n",
    "add_missing_subdirs_to_readme(d, missing_dirs)\n",
    "all_missing_dirs += missing_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "459d3f58-9ca9-4668-935d-b33eaf649b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://github.com/pclavell/project_template/tree/fairlie/\n",
      "http://github.com/pclavell/project_template/\n"
     ]
    }
   ],
   "source": [
    "print(get_branch_url())\n",
    "print(load_resources()['gh_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac8093c6-13c0-43b6-855e-23f83276827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "['analysis/template.R', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "# replace all README links using the GH url for correct branch, if neccessary\n",
    "for readme in Path(f'../').rglob('README.md'):\n",
    "       \n",
    "    # repo_path = Path(str(readme).split('../')[1]).parents[0]\n",
    "    repo_path = readme.parents[0]\n",
    "    print(repo_path)\n",
    "    \n",
    "    files = [str(f).split('../')[1] for f in repo_path.rglob('*')]\n",
    "    files = sorted(files, key=lambda f: len(Path(f).parts), reverse=True)\n",
    "    print(files)\n",
    "    \n",
    "    # parse readme to see if any of these files are mentioned here\n",
    "    with open(readme, 'r') as infile:\n",
    "    #     for line in infile:\n",
    "            \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01088f-20db-4219-b127-585ae7c9e524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7e977-c8a6-4b51-99aa-dd0bf5e00c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ee1a00-def3-4c35-b4a3-faeeb1881823",
   "metadata": {},
   "source": [
    "## testing gh workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a2f45e4-dc67-479a-8127-105755cead54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: Link Files in README\n",
      "\n",
      "on:\n",
      "  push:\n",
      "    paths:\n",
      "      - 'resources/TEST.md'  # Change to '**/*.md' after testing\n",
      "\n",
      "jobs:\n",
      "  link-files:\n",
      "    runs-on: ubuntu-latest\n",
      "    steps:\n",
      "      - uses: actions/checkout@v3\n",
      "\n",
      "      - name: Replace references to analysis/template.R\n",
      "        uses: richardrigutins/replace-in-files@v2\n",
      "        with:\n",
      "          files: 'resources/TEST.md'\n",
      "          use-regex: true\n",
      "          search-text: |\n",
      "            (?<!\\[`?)(?<!\\[)`?(analysis/template\\.R)`?(?!`\\]?)(?!\\])(\\([^\\)]*\\))?\n",
      "          replacement-text: |\n",
      "            [\\1](http://github.com/pclavell/project_template/tree/fairlie/analysis/template.R)\n",
      "    \n",
      "      - name: Replace references to analysis\n",
      "        uses: richardrigutins/replace-in-files@v2\n",
      "        with:\n",
      "          files: 'resources/TEST.md'\n",
      "          use-regex: true\n",
      "          search-text: |\n",
      "            (?<!\\[`?)(?<!\\[)`?(analysis)`?(?!`\\]?)(?!\\])(\\([^\\)]*\\))?\n",
      "          replacement-text: |\n",
      "            [\\1](http://github.com/pclavell/project_template/tree/fairlie/analysis)\n",
      "    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../../.github/workflows/link-files-test.yml')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Example get_branch_url function\n",
    "def get_branch_url():\n",
    "    return \"http://github.com/pclavell/project_template/tree/fairlie/\"\n",
    "\n",
    "# Your files list\n",
    "files = [\n",
    "    'analysis/template.R',\n",
    "    'analysis'\n",
    "]\n",
    "\n",
    "files = [Path(f) for f in files]\n",
    "repo_path = Path('.')  # adjust if needed\n",
    "\n",
    "# Convert to relative POSIX paths\n",
    "files_rel = [f.relative_to(repo_path).as_posix() for f in files]\n",
    "\n",
    "# Build a separate step for each file\n",
    "steps_yaml = \"\"\n",
    "for f in files_rel:\n",
    "    escaped_file = re.escape(f)\n",
    "    # Regex for this file\n",
    "    # regex = rf'(?<!\\[`?)(?<!\\[)`?({escaped_file})`?(?!`\\]?)(?!\\])(\\([^\\)]*\\))'\n",
    "    regex = rf'(?<!\\[`?)(?<!\\[)`?({escaped_file})`?(?!`\\]?)(?!\\])(\\([^\\)]*\\))?'\n",
    "    replacement = f\"[\\\\1]({get_branch_url()}{f})\"\n",
    "    \n",
    "    step = f\"\"\"\n",
    "      - name: Replace references to {f}\n",
    "        uses: richardrigutins/replace-in-files@v2\n",
    "        with:\n",
    "          files: 'resources/TEST.md'\n",
    "          use-regex: true\n",
    "          search-text: |\n",
    "            {regex}\n",
    "          replacement-text: |\n",
    "            {replacement}\n",
    "    \"\"\"\n",
    "    steps_yaml += step\n",
    "\n",
    "# Full GitHub Action YAML\n",
    "yaml_snippet = f\"\"\"\n",
    "name: Link Files in README\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    paths:\n",
    "      - 'resources/TEST.md'  # Change to '**/*.md' after testing\n",
    "\n",
    "jobs:\n",
    "  link-files:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "{steps_yaml}\n",
    "\"\"\"\n",
    "\n",
    "print(yaml_snippet)\n",
    "\n",
    "# save\n",
    "workflow_dir = Path('../../.github/workflows')  # relative to resources/\n",
    "workflow_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "workflow_file = workflow_dir / 'link-files-test.yml'\n",
    "workflow_file.write_text(yaml_snippet)\n",
    "\n",
    "workflow_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4b578-b807-4c50-af99-55fa84e467cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f6f72-4348-4400-b6d4-99d12553bf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f543a6f-71cf-4637-94b1-848cad328e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060f884-76a0-4749-95ff-93af9ba1838f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87da1b3a-1055-4cf6-a71e-e8a75ca40b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build one regex that matches any file in backticks or brackets\n",
    "# import re\n",
    "# # files = ['analysis/template.R', 'resources/resources.yml', 'resources']\n",
    "# files = ['analysis']\n",
    "# escaped_files = [re.escape(f) for f in files]\n",
    "# pattern = r'(`(' + '|'.join(escaped_files) + r')`|\\[(' + '|'.join(escaped_files) + r')\\])'\n",
    "# pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87a6f0aa-11b0-44bd-8069-bbc4f03dcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readme = 'TEST.md'\n",
    "\n",
    "# files = [str(f).split('../')[1] for f in repo_path.rglob('*')]\n",
    "# files = sorted(files, key=lambda f: len(Path(f).parts), reverse=True)\n",
    "# print(files)\n",
    "\n",
    "# for f in files:\n",
    "#     lines = []\n",
    "#     with open(readme, 'r') as infile:\n",
    "#         for line in infile:\n",
    "#             # if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379c8de-8129-4d12-b757-6b3894ef3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ping to check for broken links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad08b6-b672-4239-9d80-bb82c15c49da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15856c5-6a7e-4af4-88b5-8d9242d9b29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
